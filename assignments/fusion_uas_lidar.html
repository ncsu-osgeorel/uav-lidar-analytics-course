<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>GIS595/MEA792: UAV/lidar Data Analytics</title>

<link rel="shortcut icon" href=".././img/favicon.ico" />

<link href="../layout.css" rel="stylesheet" type="text/css" media="screen">
<link href="../style.css" rel="stylesheet" type="text/css" media="screen">

</head>

<body>

<div id="outercontainer">
<div id="container">

<header>
<div id="header-image">
    <h1>GIS595/MEA792:<br>UAV/lidar Data Analytics</h1>
</div>

<nav>
<ul class="nav">
<li><a href="../index.html">Syllabus</a></li>
<li><a href="../schedule.html">Schedule</a></li>
<li><a href="../lectures.html">Lectures</a></li>
<li><a href="../assignments.html">Assignments</a></li>
<li><a href="../projects.html">Projects</a></li>
</ul>
</nav>

</header>

<main>
<!-- This is a generated file. Do not edit. -->
<div style="background-color: #FA8; border: 4px solid #F00; padding: 10px;"><p>This is an unmaintained course material, please see current material at:<ul><li><a href="https://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/">https://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/</a></li><li><a href="https://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/assignments/fusion_uas_lidar.html">https://ncsu-geoforall-lab.github.io/uav-lidar-analytics-course/assignments/fusion_uas_lidar.html</a> (likely URL)</li></ul></div>
<h2>Fusion of uas and lidar data</h2>

Outline:

<ul>
    <li>analyze the differences between the lidar and uas DEM/DSM
    <li>fuse lidar and uas DSM for viewshed analysis: compare simple patching with map algebra 
        with reinterpolation from maximum elevation points
</ul>

Data: 

<ul>
    <li>you should already have both the lidar and uas DSMs and points clouds.
    <li><a href="./resources/fields.pack">Fields polygon as packed raster</a> use r.unpack in your mapset to import it
</ul>
<p>
Tools:

<ul>
    <li>
        Your <a href="http://wingrass.fsv.cvut.cz/grass70/">GRASS GIS 7</a>
        installation should also include <a href="http://www.liblas.org/">libLAS</a> library
        which is used by GRASS modules v.in.lidar and r.in.lidar
        (standalone GRASS GIS for MS Windows, OSGeo4W and Ubuntu packages contain libLAS).
    </li>
    <li>libLAS installation should include command line tools lasinfo and las2txt.
</ul>

<h3>Analyze the difference between the lidar and UAS DSM </h3>

First we need to evaluate the DSMs to find out which are suitable for fusion
<ul>
 <li> compare errors at GCPs (lidar, agisoft, trimble or pix4d in june)
 <li> compute the difference between lidar DSM and selected uas: raster, profile/difference along a road and roof
 <li> use above to identify potential systematic error (you will see approx constant shift in profiles
and most difs have the same sign, use mean or median as syst. error estimate, re-do the profile
to verify the correction), use Mitasova et al. 2009 for reference
 <li> identify distortions - use corrected dsm and lid-uav diff, 
 look for unexpected pattern, verify with profile.
 Put into report and exclude distorted areas from study area.
 Why are the distortions / errors low along the road but high in the fields?
 What would you have to do if you needed to correct the distorted area
(add gcps using stable features in lidar and reprocess)
 <li> now you have two DSMs: corrected lidar DSM and (corrected) low-distortion subset of UAS DSM:
      create a new DSM for the entire area using at least two approaches
      and compare how the two approaches work for viewshed mapping
</ul>

Suggested color table for differences, used in the workflow as dif_lidar_uav.txt:

<pre data-filename="dif_lidar_uav.txt"><code> -40 red
 -1 orange
 -0.5 yellow
 -0.1 grey
 0 white
 0.1 grey
 0.5 cyan
 1 aqua
 35 blue
</code></pre>

Compute the differences between the lidar and uav DSMs

<pre><code>g.region rast=mid_pines_lidar2013_dsm -p
r.mapcalc "diff_lidardsm_agi_june = mid_pines_lidar2013_dsm - 2015_06_20_DSM_agi_11GCP"
r.colors diff_lidardsm_agi_june rules=dif_lidar_uav.txt
r.mapcalc "diff_lidardsm_pix4d_june = mid_pines_lidar2013_dsm - 2015_06_20_pix4d_11GCP_dsm"
r.colors diff_lidardsm_pix4d_june rules=dif_lidar_uav.txt
</code></pre>

Evaluate possible systematic shift along stable features using the profile tool or the following commands

<pre><code>r.profile -g input=diff_lidardsm_agi_june output=road.txt coordinates=637208,219491,637059,219734
v.in.ascii input=road.txt output=profile_road separator=space columns="x double,y double,profile double,diff double"
v.univar map=profile_road column=diff
</code></pre>

Because the shift in lidar is small we will ignore it in our first set of fusion examples, but we will
use the analysis above top select the region with minimal distortion in the UAS DSM and compute clipped DSM

<pre><code>g.region n=219720.9 s=219257.1 w=636762.9 e=637190.4 res=0.3 -p
r.mapcalc "2015_06_20_DSM_agi_11GCP_cl = 2015_06_20_DSM_agi_11GCP"
</code></pre>

Patch UAS DSM with lidar DSM to cover the entire Mid Pines study area and use shaded relief 
to check for patch edges

<pre><code>g.region rast=mid_pines_lidar2013_dsm -p
r.patch 2015_06_20_DSM_agi_11GCP_cl,mid_pines_lidar2013_dsm out=lid_uas_patch
r.relief lid_uas_patch out=lid_uas_patchsh
</code></pre>

We have visible discontinuity along the patch edges so we will use map algebra to do
the patching with averaged overlap.
First we define a region for 6m (20 cell) overlap (you can do this also interactively using mouse)
<pre><code>g.region rast=2015_06_20_DSM_agi_11GCP_cl -p
g.region s=s-6 n=n+6 e=e+6 w=w-6 -p 
</code></pre>

Then, within this region, we compute a raster with lidar+uas DSM average in the overlap and UAS elsehwere
<pre><code>r.mapcalc "lid_uas_overlap_avg = if(isnull(2015_06_20_DSM_agi_11GCP_cl),(2015_06_20_DSM_agi_11GCP+mid_pines_lidar2013_dsm)/2.,2015_06_20_DSM_agi_11GCP_cl)"
</code></pre>

We can now merge it with lidar for entire study area and check the patch edges using shaded relief
<pre><code>g.region rast=mid_pines_lidar2013_dsm
r.mapcalc "lidar_uas_mergedavg = if(isnull(lid_uas_overlap_avg), mid_pines_lidar2013_dsm, lid_uas_overlap_avg)"
r.relief lidar_uas_mergedavg out=lidar_uas_mergedavgsh
</code></pre>
<p>
We now have smoother transition from UAS to lidar, but you can still identify two edges when viewing the patched DSM
in 3D view (nviz). Therefore we will use weighted average to smooth out the overlap with the following workflow
(try to explain it in your report):

<pre><code>g.region rast=2015_06_20_DSM_agi_11GCP_cl -p
g.region s=s+10 n=n-10 e=e-10 w=w+10 -p
r.mapcalc "dummy = 1"
g.region rast=2015_06_20_DSM_agi_11GCP_cl -p
r.grow.distance -m input=dummy distance=distance
g.region rast=mid_pines_lidar2013_dsm
r.mapcalc "patched_smooth = if(isnull(distance), mid_pines_lidar2013_dsm, (1 - distance/10.) * 2015_06_20_DSM_agi_11GCP_cl +(distance/10) * mid_pines_lidar2013_dsm)"
</code></pre>


We will create a smooth transition when modeling the flow using a different method, in this assignment
we will explore the viewshed analysis.

<p>
We would like to set up a webcam to monitor this area 
during the growing season so we need to update the lidar-based DSM with the  UAS data and
analyze the viewshed while taking into account the corn growing in the field.
First we need to make sure that we take into account entire field
to create a lidar-based DSM updated in the fields using UAS data.
You can use digitizer to create a polygon or 
get the packed raster representation of fields from the link above.

<pre><code>r.unpack -o fields.pack
r.mapcalc "uas_june_clpol = 2015_06_20_DSM_agi_11GCP * fields" 
r.patch uas_june_clpol,mid_pines_lidar2013_dsm out=lid_uas_patch_polygon 
r.relief lid_uas_patch_polygon out=lid_uas_patch_polygonsh 
</code></pre>

We compute viewshed from the point 637100,219360 using
lidar only, uas only, and patched lidar+uas, 
<pre><code>r.viewshed input=mid_pines_lidar2013_dsm output=viewshed_lidar coordinates=637100,219360
r.viewshed input=2015_06_20_DSM_agi_11GCP output=viewshed_uas coordinates=637100,219360
r.viewshed input=lid_uas_patch_polygon output=viewshed_liduaspatchpoly coordinates=637100,219360 --o
r.colors viewshed_lidar co=reds
r.colors viewshed_uas co=greens
r.colors viewshed_liduaspatchpoly co=blues
</code></pre>
To compare the viewsheds display the resulting maps with transparency.
Discuss the result.
<p>
Note: To find the location and height of the webcam that will capture the entire field during entire
year we can run r.series on the time series of UAS DSMs to derive the DSM envelope surface
and use it to analyze the viewshed. Of course, this assumes that the crops will be the same
the following year.

<!--
r.viewshed input=lid_uas_patch output=viewshed_liduas coordinates=637100,219360
r.viewshed input=lidar_uas_mergedavg output=viewshed_liduasavg coordinates=637100,219360
-->


<p>
Further reading:
<p>
Fusion of multi-scale DEMs using a regularized super-resolution method.<br>
Linwei Yue , Huanfeng Shen , Qiangqiang Yuan , Liangpei Zhang.<br>
International Journal of Geographical Information Science.
Vol. 29, Iss. 12, 2015

</main>

<footer>

<nav>
<ul>
<li>
    <a href="https://github.com/ncsu-osgeorel/uav-lidar-analytics-course" title="Fork on GitHub">
        <img src="../img/github_logo.png" alt="GitHub Octocat logo">
    </a>
</li>
<li title="Copyright and license (not applicable to linked materials)">
    &copy; 2015
    <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA</a>
    <a href="http://geospatial.ncsu.edu/osgeorel/">NCSU OSGeoREL</a>
</li>
</ul>
</nav>

</footer>

</div>
</div>

</body>
</html>
